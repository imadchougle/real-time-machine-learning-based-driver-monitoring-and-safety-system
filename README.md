# Real-time Machine Learning-Based Driver Monitoring and Safety System

**Title: Real-time Machine Learning-Based Driver Monitoring and Safety System**
**ML Driver’s Shield or MLDS**

**Abstract:** This Project aims to create a Real time Machine Learning Based smart system that watches over drivers in real-time to keep them safe on the road by actively monitoring driver behaviour and taking preventive actions when necessary. Driver’s drowsiness and fatigue are the main reasons for most of the accident happening on the road. To overcome this problem and solve this, MLDS notifies the driver when signs of drowsiness are detected by a voice alert system and an audible alarm. MLDS uses Deep Learning technology, specifically CNN, for its operations. Even though cars have safety features like airbags, accidents still happen and sometimes it takes too long for help to arrive. The system can accurately detect the driver's eye status, monitor yawning patterns, and even respond by sending automatic notifications to the driver's relatives or friends if an airbag is deployed i.e., in case of accidents.  


**Introduction:** The National Highway Traffic Safety Administration estimates that 100,000 accidents are the direct result of driver fatigue each year. 21 percent of all fatal accidents are due to drowsy driving. This Project aims to identify the driver’s drowsiness using Deep Learning techniques and alert the driver. This project uses a custom dataset built using images of my eyes and face. In this multifaceted project, it addresses three critical aspects of driver safety using a pretrained machine learning model renowned for its speed and accuracy, MobileNet, with the implementation of transfer learning. Task 1: Driver's Eye Status Monitoring: First task involves the real-time monitoring of the driver's eye status. By continuously analyse the driver's eyes. If the system detects closed eyes, it alerts the driver using an integrated alarm system. Task 2: Airbag Status Monitoring: a system to continuously monitor the status of the airbags. I have used a custom dataset comprising images of airbags deployed and non-deployed states for training. Employing CNN for image classification, to accurately determine whether the airbags have been deployed in case of accident. Then the system automatically sends alert messages to the driver's friends and relatives notifying them about the situation. Task 3: Yawn Detection: monitoring the driver's yawning behaviour as an indicator of fatigue. An innovative algorithm that identifies the driver's face and measures the distance between the upper and lower lips. When this distance surpasses a predefined threshold value, it signals a yawn and alerts the driver. What makes this project especially impressive is the System runs all three tasks at the same time in real-time, using just one camera to capture everything. It does this quickly and accurately. So, it always keeps an eye on the driver, the airbags, and yawning all at once to make sure everyone stays safe. By integrating these three vital components my project aims to enhance driver safety and provide peace of mind for both drivers and their loved ones
